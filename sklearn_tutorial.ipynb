{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd02c8ae7b7397383be484f509670a744b7a75aaa69a8c48f2fc2b876db86f77bea",
   "display_name": "Python 3.8.8 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "2c8ae7b7397383be484f509670a744b7a75aaa69a8c48f2fc2b876db86f77bea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Sklearn Tutorial\n",
    "\n",
    "This notebook was created durring the Spring semester of 2021 while doing research funded by XSEDE. \n",
    "This notebook in particular was a simplified and cleaned up version of our research source code that can be used as a template for learning the framework. We will also look into other python libraries like pandas and pickle \n",
    "### Goal:\n",
    "In this notebook we will be using astronomical data from pulsars. The goal is to create a model that can accuratly predict if the data collected is from a pulsar or from Radio Frequency Interference (RFI). In machine learning, this is reffered to as a classification problem where we have input variables and need to group them into different classes. In this case, we have 2 classes: Pulsars and RFI.\n",
    "<br>\n",
    "Pictures of Pulsars:\n",
    "<br>\n",
    "<img src=\"notebook_data/pulsar_picture.jpg\" style=\"height:200px\">\n",
    "<img src=\"notebook_data/pulsar_picture2.jpg\" style=\"height:200px\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Getting Current Working Directory\n",
    "I've found that using local paths to files is a little buggy while using the pickles library. So, to aliviate the problem, we will use an absolute path by getting the current working directory and then joining that path to the local path when we load and save files. For more information on this you can read this article by [TutorialsPoint](https://www.tutorialspoint.com/python/os_getcwd.htm)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "here = os.getcwd()"
   ]
  },
  {
   "source": [
    "## Pandas and the HTRU Dataset\n",
    "Pandas is a Python library that provides helpful datastructures and functions to manipulate the data. The main structure is called a dataframe. The way we used this structure was basically a 2D array that holds our data. For more information on the Pandas library, check out [pandas documentation](https://pandas.pydata.org/docs/). It is also convention to import pandas as pd. This shorthand allows us to more quickly use pandas methods without having to type out 'pandas' every time we use it.\n",
    "<br><br>\n",
    "Now we need to load our dataset into a pandas dataframe. The dataset we will be using is the HTRU dataset. This is a clean dataset that has 8 input values and a class label for over 17,000 pieces of data. You can find and download the set [here](https://www.kaggle.com/charitarth/pulsar-dataset-htru2). However, it is also provided in this repository saved as a csv file. The folks that created this open-source dataset requested any work that uses it provides the following citation: \n",
    "<br><br>\n",
    "R. J. Lyon, B. W. Stappers, S. Cooper, J. M. Brooke, J. D. Knowles, Fifty Years of Pulsar\n",
    "<br>\t&emsp; Candidate Selection: From simple filters to a new principled real-time classification approach\n",
    "<br>\t&emsp; MNRAS, 2016.\n",
    "\n",
    "<br>\n",
    "For more information on the dataset, you can also check out the detailed documentation I found on [their website](https://archive.ics.uci.edu/ml/datasets/HTRU2). This is also provided in this repository under htru_citation.txt."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     140.5625  55.68378214  -0.234571412  -0.699648398  3.199832776  \\\n",
       "0  102.507812    58.882430      0.465318     -0.515088     1.677258   \n",
       "1  103.015625    39.341649      0.323328      1.051164     3.121237   \n",
       "2  136.750000    57.178449     -0.068415     -0.636238     3.642977   \n",
       "3   88.726562    40.672225      0.600866      1.123492     1.178930   \n",
       "4   93.570312    46.698114      0.531905      0.416721     1.636288   \n",
       "\n",
       "   19.11042633  7.975531794  74.24222492  0  \n",
       "0    14.860146    10.576487   127.393580  0  \n",
       "1    21.744669     7.735822    63.171909  0  \n",
       "2    20.959280     6.896499    53.593661  0  \n",
       "3    11.468720    14.269573   252.567306  0  \n",
       "4    14.545074    10.621748   131.394004  0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>140.5625</th>\n      <th>55.68378214</th>\n      <th>-0.234571412</th>\n      <th>-0.699648398</th>\n      <th>3.199832776</th>\n      <th>19.11042633</th>\n      <th>7.975531794</th>\n      <th>74.24222492</th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>102.507812</td>\n      <td>58.882430</td>\n      <td>0.465318</td>\n      <td>-0.515088</td>\n      <td>1.677258</td>\n      <td>14.860146</td>\n      <td>10.576487</td>\n      <td>127.393580</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>103.015625</td>\n      <td>39.341649</td>\n      <td>0.323328</td>\n      <td>1.051164</td>\n      <td>3.121237</td>\n      <td>21.744669</td>\n      <td>7.735822</td>\n      <td>63.171909</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>136.750000</td>\n      <td>57.178449</td>\n      <td>-0.068415</td>\n      <td>-0.636238</td>\n      <td>3.642977</td>\n      <td>20.959280</td>\n      <td>6.896499</td>\n      <td>53.593661</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>88.726562</td>\n      <td>40.672225</td>\n      <td>0.600866</td>\n      <td>1.123492</td>\n      <td>1.178930</td>\n      <td>11.468720</td>\n      <td>14.269573</td>\n      <td>252.567306</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>93.570312</td>\n      <td>46.698114</td>\n      <td>0.531905</td>\n      <td>0.416721</td>\n      <td>1.636288</td>\n      <td>14.545074</td>\n      <td>10.621748</td>\n      <td>131.394004</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# pandas .read_csv() method saves a csv file into a pandas dataframe\n",
    "data_frame = pd.read_csv(os.path.join(here, 'HTRU_2.csv'))\n",
    "\n",
    "# .head() lets us look at the structure of the dataframe and the first 5 rows\n",
    "data_frame.head() "
   ]
  },
  {
   "source": [
    "## Missing Column Headers\n",
    "Notice that there are no column labels in the current dataframe. It bassically used the first piece of data as the column headers. We need to update the column headers with more useful headers. As described by the dataset creaters, the following are what each column corrisponds to:\n",
    "\n",
    "<ol>\n",
    "    <li>Mean of integrated profile</li>\n",
    "\t<li>Standard deviation of the integrated profile</li>\n",
    "\t<li>Excess kurtosis of the integrated profile</li>\n",
    "\t<li>Skewness of the integrated profile</li>\n",
    "\t<li>Mean of the DM-SNR curve</li>\n",
    "\t<li>Standard deviation of the DM-SNR curve</li>\n",
    "\t<li>Excess kurtosis of the DM-SNR curve</li>\n",
    "\t<li>Skewness of the DM-SNR curve</li>\n",
    "\t<li>Class</li>\n",
    "</ol>\n",
    "So, we will update the column headers of our data frame to better represent the above."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Mean of Int. Prof.  Stand. Deviation of Int. Prof.  \\\n",
       "0          102.507812                       58.882430   \n",
       "1          103.015625                       39.341649   \n",
       "2          136.750000                       57.178449   \n",
       "3           88.726562                       40.672225   \n",
       "4           93.570312                       46.698114   \n",
       "\n",
       "   Excess Kurtosis of Int. Prof.  Skewness of Int. Prof.  Mean of Curve  \\\n",
       "0                       0.465318               -0.515088       1.677258   \n",
       "1                       0.323328                1.051164       3.121237   \n",
       "2                      -0.068415               -0.636238       3.642977   \n",
       "3                       0.600866                1.123492       1.178930   \n",
       "4                       0.531905                0.416721       1.636288   \n",
       "\n",
       "    Stand. Deviation of Curve  Excess Kurtosis of Curve  Skewness of Curve  \\\n",
       "0                   14.860146                 10.576487         127.393580   \n",
       "1                   21.744669                  7.735822          63.171909   \n",
       "2                   20.959280                  6.896499          53.593661   \n",
       "3                   11.468720                 14.269573         252.567306   \n",
       "4                   14.545074                 10.621748         131.394004   \n",
       "\n",
       "   Class  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Mean of Int. Prof.</th>\n      <th>Stand. Deviation of Int. Prof.</th>\n      <th>Excess Kurtosis of Int. Prof.</th>\n      <th>Skewness of Int. Prof.</th>\n      <th>Mean of Curve</th>\n      <th>Stand. Deviation of Curve</th>\n      <th>Excess Kurtosis of Curve</th>\n      <th>Skewness of Curve</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>102.507812</td>\n      <td>58.882430</td>\n      <td>0.465318</td>\n      <td>-0.515088</td>\n      <td>1.677258</td>\n      <td>14.860146</td>\n      <td>10.576487</td>\n      <td>127.393580</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>103.015625</td>\n      <td>39.341649</td>\n      <td>0.323328</td>\n      <td>1.051164</td>\n      <td>3.121237</td>\n      <td>21.744669</td>\n      <td>7.735822</td>\n      <td>63.171909</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>136.750000</td>\n      <td>57.178449</td>\n      <td>-0.068415</td>\n      <td>-0.636238</td>\n      <td>3.642977</td>\n      <td>20.959280</td>\n      <td>6.896499</td>\n      <td>53.593661</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>88.726562</td>\n      <td>40.672225</td>\n      <td>0.600866</td>\n      <td>1.123492</td>\n      <td>1.178930</td>\n      <td>11.468720</td>\n      <td>14.269573</td>\n      <td>252.567306</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>93.570312</td>\n      <td>46.698114</td>\n      <td>0.531905</td>\n      <td>0.416721</td>\n      <td>1.636288</td>\n      <td>14.545074</td>\n      <td>10.621748</td>\n      <td>131.394004</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "data_frame.columns =['Mean of Int. Prof.', 'Stand. Deviation of Int. Prof.', \n",
    "                     'Excess Kurtosis of Int. Prof.', 'Skewness of Int. Prof.',\n",
    "                     'Mean of Curve', ' Stand. Deviation of Curve', 'Excess Kurtosis of Curve',\n",
    "                     'Skewness of Curve', 'Class']\n",
    "\n",
    "# Now that we added column headers lets look at the header\n",
    "data_frame.head()"
   ]
  },
  {
   "source": [
    "## Looking Closer at Our Data\n",
    "Now that we have imported our data and cleaned up the column headers, we need to make sure the dataset itself is clean. The two things we need to check for are duplicates in the data and holes in our data. There are a few helpful methods in the pandas library that will help us check our dataset very easily. Let's start by checking the shape of our dataframe using pandas .shape. This will tell us how many objects there are in the dataset and how many attributes each object has."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(17897, 9)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "data_frame.shape"
   ]
  },
  {
   "source": [
    "As seen above, our dataframe has 17,897 different objects that are either pulsars or RFI. And each object has 9 attributes which would be the 8 attributes plus the class label. \n",
    "<br>\n",
    "Now, let's make sure that there are no duplicates in the data. We will do this by using the pandas method [.drop_duplicates().](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html) We can then check the shape again to see if any duplicates were found."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Before dropping duplicates: (17897, 9)\nAfter dropping duplicates:  (17897, 9)\n"
     ]
    }
   ],
   "source": [
    "print('Before dropping duplicates: ' + str(data_frame.shape))\n",
    "data_frame = data_frame.drop_duplicates()\n",
    "print('After dropping duplicates:  ' + str(data_frame.shape))"
   ]
  },
  {
   "source": [
    "As you can see, there was no change in the number of objects in the data frame. This means there were no duplicates found in the dataset. If you do come accross a dataset that has duplicates, it is important to drop them so your model will not be biased towards those objects.\n",
    "<br>\n",
    "Next, let's check for fields with missing data. for this, we will use the [.isnull()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.isnull.html) method that will flag the objects with missing data by creating a boolean data frame marking which elements are missing. We will then use the [.sum()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sum.html) function to count up the number of missing data in each column and display the totals for each column."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Mean of Int. Prof.                0\n",
       "Stand. Deviation of Int. Prof.    0\n",
       "Excess Kurtosis of Int. Prof.     0\n",
       "Skewness of Int. Prof.            0\n",
       "Mean of Curve                     0\n",
       " Stand. Deviation of Curve        0\n",
       "Excess Kurtosis of Curve          0\n",
       "Skewness of Curve                 0\n",
       "Class                             0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "data_frame.isnull().sum() "
   ]
  },
  {
   "source": [
    "Since all of the columns have no missing data, we can safely move forward with this dataset. If you do run into a dataset that has missing data you can use panda method [.dropna()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html?highlight=dropna)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Distribution of Data\n",
    "Lets look at the distribution of our data between the two classes (pulsars vs non-pulsars). To do this, I made a dataframe that has all the pulsars in it and a data frame with the non pulsars in it. From there, if you just take the length of both, you can print the distribution."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of Non-Pulsars: 16258\nNumber of Pulsars:     1639\nRatio of Pulsars: 0.09157959434542103\n"
     ]
    }
   ],
   "source": [
    "# To break down what is done in these 2 lines\n",
    "# data_frame[data_frame.Class == 0] returns\n",
    "# a dataframe including all of the rows with a class 0\n",
    "# len simply returns the length of such a dataframe\n",
    "\n",
    "# a class of 0 is non pulsar and 1 is pulsar\n",
    "print('Number of Non-Pulsars: ' + str(len(data_frame[data_frame.Class == 0])))\n",
    "print('Number of Pulsars:     ' + str(len(data_frame[data_frame.Class == 1])))\n",
    "print('Ratio of Pulsars: ' + str(1639/(16258+1639)))\n"
   ]
  },
  {
   "source": [
    "Here is a pie chart to better visualize the data:\n",
    "<br>\n",
    "<img src='notebook_data/pie_chart1.png'>\n",
    "<br>\n",
    "There is obviously an inbalance here. Over 90% of the data is in one class. We need to be careful that this inbalance will not bias our model too much. This means the model will favor classifying any new data as RFI which will lead to more missed predictions of pulsars. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Creating Input and Output data frames\n",
    "The next step in the process is to separate the inputs from the ouputs. In this case, columns 1-8 are inputs and the outputs are in the last column (Class). So, we need to save the first 8 columns into a separate data frame from the last column. We will label the input data frame as x and the output data frame as y.\n",
    "<br>\n",
    "To create the input data frame, we can use the pandas function [.drop()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html). The goal is to create a copy of our dataframe and drop the last column. \n",
    "<br>\n",
    "To create the output data frame, we can use the pandas function [.loc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html) to access the Class column and save it to y."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(17897, 8)\n(17897, 1)\n"
     ]
    }
   ],
   "source": [
    "# axis 1 represents the columns (obviously axis 0 will represent the rows)\n",
    "# inplace determines whether or not what is returned is a modified copy or \n",
    "# if the operation is done on the original dataframe\n",
    "# since we want to save a modified copy we set inplace=False\n",
    "x = data_frame.drop(['Class'], axis=1, inplace=False)\n",
    "\n",
    "# Now let's grab the class column for our output vector\n",
    "# the first parameter controls which rows we want, and the second controls the columns we want\n",
    "# in our case, we want all the rows and the Class column\n",
    "y = data_frame.loc[:, ['Class']]\n",
    "\n",
    "# Let's look at the shape and see if they match our expectations\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "source": [
    "Just to double check our work, let's look at the heads of each data frame to see what these operations did. As you can see below, x has all of the input columns and y has the output columns as we expected."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Mean of Int. Prof.  Stand. Deviation of Int. Prof.  \\\n",
       "0          102.507812                       58.882430   \n",
       "1          103.015625                       39.341649   \n",
       "2          136.750000                       57.178449   \n",
       "3           88.726562                       40.672225   \n",
       "4           93.570312                       46.698114   \n",
       "\n",
       "   Excess Kurtosis of Int. Prof.  Skewness of Int. Prof.  Mean of Curve  \\\n",
       "0                       0.465318               -0.515088       1.677258   \n",
       "1                       0.323328                1.051164       3.121237   \n",
       "2                      -0.068415               -0.636238       3.642977   \n",
       "3                       0.600866                1.123492       1.178930   \n",
       "4                       0.531905                0.416721       1.636288   \n",
       "\n",
       "    Stand. Deviation of Curve  Excess Kurtosis of Curve  Skewness of Curve  \n",
       "0                   14.860146                 10.576487         127.393580  \n",
       "1                   21.744669                  7.735822          63.171909  \n",
       "2                   20.959280                  6.896499          53.593661  \n",
       "3                   11.468720                 14.269573         252.567306  \n",
       "4                   14.545074                 10.621748         131.394004  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Mean of Int. Prof.</th>\n      <th>Stand. Deviation of Int. Prof.</th>\n      <th>Excess Kurtosis of Int. Prof.</th>\n      <th>Skewness of Int. Prof.</th>\n      <th>Mean of Curve</th>\n      <th>Stand. Deviation of Curve</th>\n      <th>Excess Kurtosis of Curve</th>\n      <th>Skewness of Curve</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>102.507812</td>\n      <td>58.882430</td>\n      <td>0.465318</td>\n      <td>-0.515088</td>\n      <td>1.677258</td>\n      <td>14.860146</td>\n      <td>10.576487</td>\n      <td>127.393580</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>103.015625</td>\n      <td>39.341649</td>\n      <td>0.323328</td>\n      <td>1.051164</td>\n      <td>3.121237</td>\n      <td>21.744669</td>\n      <td>7.735822</td>\n      <td>63.171909</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>136.750000</td>\n      <td>57.178449</td>\n      <td>-0.068415</td>\n      <td>-0.636238</td>\n      <td>3.642977</td>\n      <td>20.959280</td>\n      <td>6.896499</td>\n      <td>53.593661</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>88.726562</td>\n      <td>40.672225</td>\n      <td>0.600866</td>\n      <td>1.123492</td>\n      <td>1.178930</td>\n      <td>11.468720</td>\n      <td>14.269573</td>\n      <td>252.567306</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>93.570312</td>\n      <td>46.698114</td>\n      <td>0.531905</td>\n      <td>0.416721</td>\n      <td>1.636288</td>\n      <td>14.545074</td>\n      <td>10.621748</td>\n      <td>131.394004</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Class\n",
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "source": [
    "## Separate Data Into Testing and Training Sets\n",
    "The next step is to separate our data into a training set and a testing set. This way we can train our model and then test the accuracy based on new data (data the model hasn't seen yet). This practice will help us get more acurate representation of how the model will act on new data. \n",
    "<br>\n",
    "Sklearn has a function [.train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) that splits the data frames for us. The method returns 4 data frames in total: training inputs, testing inputs, training outputs and testing outputs. The parameter test_size determines what percentage of the dataframe is used for testing. In our case we used 20% for testing. This leaves 80% of our data to train off of. The parameter random_state is the seed for the sudo-random number generator for shuffling data. The documentation said 42 was a common seed to use so we will use that."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "14317\n14317\n3580\n3580\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, random_state=42)\n",
    "\n",
    "# Let's look at the size of the different dataframes to see what the function did\n",
    "print((x_train.size)//8) # divide by 8 because there are 8 columns (// is integer division in python)\n",
    "print(y_train.size)\n",
    "print((x_test.size)//8) # divide by 8 because there are 8 columns\n",
    "print(y_test.size)"
   ]
  },
  {
   "source": [
    "Let's make sure that the test and training sets contain a similar ratio of pulsars to non pulsars."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TRAINING SET STATS:\nNumber of Non-Pulsars=12999\nNumber of Pulsars=1318\nRatio of Pulsars=0.09205839212125445\n\nTESTING SET STATS:\nNumber of Non-Pulsars=3259\nNumber of Pulsars=321\nRatio of Pulsars=0.08966480446927375\n"
     ]
    }
   ],
   "source": [
    "non_pulsar_train = len(y_train[y_train.Class == 0])\n",
    "pulsar_train = len(y_train[y_train.Class == 1])\n",
    "percent_pusar_train = pulsar_train/(non_pulsar_train+pulsar_train)\n",
    "\n",
    "non_pulsar_test = len(y_test[y_test.Class == 0])\n",
    "pulsar_test = len(y_test[y_test.Class == 1])\n",
    "percent_pusar_test = pulsar_test/(non_pulsar_test+pulsar_test)\n",
    "\n",
    "print(\"TRAINING SET STATS:\")\n",
    "print('Number of Non-Pulsars=' + str(non_pulsar_train))\n",
    "print('Number of Pulsars=' + str(pulsar_train))\n",
    "print('Ratio of Pulsars=' + str(percent_pusar_train))\n",
    "print('\\nTESTING SET STATS:')\n",
    "print('Number of Non-Pulsars=' + str(non_pulsar_test))\n",
    "print('Number of Pulsars=' + str(pulsar_test))\n",
    "print('Ratio of Pulsars=' + str(percent_pusar_test))"
   ]
  },
  {
   "source": [
    "Pie charts to help with visualization (numbers will slightly vary from pie charts depending on the random split):\n",
    "<br>\n",
    "<img src ='notebook_data/pie_chart2.png'> <img src='notebook_data/pie_chart3.png'>\n",
    "\n",
    "<br>\n",
    "Both have a good distribution which are very close to each other and close to the original dataset's distribution."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Model Metrics\n",
    "We will be using 3 different metrics to gauge the effectiveness of our models. All three are from the [sklearn.metrics](https://scikit-learn.org/stable/modules/model_evaluation.html) library. The first metric is the accuracy score. This simply will give use the percentage of correct predictions our model made. This alone will not be enough to get a full idea of how accurate our model is. For example, if our model predicts RFI every time, it will be around 90% accurate. 90% sounds like a great performance, but is not a useful model. To try and get a better idea of how our model is predicting, we will also use the confusion matrix which gives us the number of each catagoriy (true positive, false positive, false negative and true negative). Another metric we will use is the f1 score which basically calculates the recall and precision and gives a score based on that (this tells us more than just the accuracy score alone)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "source": [
    "## Choosing a Model\n",
    "The sklearn library provides a ton of different models to train. In this notebook, we will only focus on an MLP Classifier [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) (Bassically a feed forward neural network). However, if you wanted to try some of the other classifiers in the sklearn library, the process would be very similar. So, first we need to import the type of model we want to use, then set the parameters. In this example, we are only changing the number and size of the hidden layers. We are leaving all of the other variables default. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# This is 3 hidden layers of 10 hidden nodes each\n",
    "neural_network = MLPClassifier(hidden_layer_sizes=(10,10,10))"
   ]
  },
  {
   "source": [
    "## Training a Model\n",
    "Once you create a model object, sklearn provides a single function to train all of their networks: [.fit](https://towardsdatascience.com/fit-vs-predict-vs-fit-predict-in-python-scikit-learn-f15a34a8d39f). The two parameters are a dataframe of the inputs for training and the outputs. Note that the outputs must be a 1D array, so if you dont use .values.ravel() it will still work but it will throw an error because it is unsure that the data frame you provided is 1D (you can read [this thread](https://stackoverflow.com/questions/34165731/a-column-vector-y-was-passed-when-a-1d-array-was-expected) for more info). Also, keep in mind that both the inputs and the outputs need to have the same number of objects in them. Otherwise, this is a very simple line of code for the complex work that is going on in the background."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(10, 10, 10))"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "# This line trains the model using the input and output of the training sets we separated before\n",
    "neural_network.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "source": [
    "## Predicting on Unseen Data and Performance Overview\n",
    "Now that we have a trained model, lets see how it performs on our test data. To do this we use the sklearn [.predict method](https://towardsdatascience.com/fit-vs-predict-vs-fit-predict-in-python-scikit-learn-f15a34a8d39f). The only parameter is the input data frame and it returns the predictions from the model. We can then use the model's predicted classifications and compare them to the actual classifications to gauge the performance of our model. We will be using accuarcy score, f1 score, and to make the confusion matrix easier to visualize, I actually made a matplotlib heatmap to show the confusion matrix."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score: 0.979050279329609\nF1 Score: [0.98854787 0.87725041]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"280.192188pt\" version=\"1.1\" viewBox=\"0 0 423.995312 280.192188\" width=\"423.995312pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-06-06T17:32:44.294019</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 280.192188 \r\nL 423.995312 280.192188 \r\nL 423.995312 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 42.395313 237.796875 \r\nL 416.795312 237.796875 \r\nL 416.795312 28.396875 \r\nL 42.395313 28.396875 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"QuadMesh_1\">\r\n    <path clip-path=\"url(#pdf9e02505e)\" d=\"M 42.395313 28.396875 \r\nL 229.595312 28.396875 \r\nL 229.595312 133.096875 \r\nL 42.395313 133.096875 \r\nL 42.395313 28.396875 \r\n\" style=\"fill:#08306b;stroke:#ffffff;stroke-width:0.5;\"/>\r\n    <path clip-path=\"url(#pdf9e02505e)\" d=\"M 229.595312 28.396875 \r\nL 416.795312 28.396875 \r\nL 416.795312 133.096875 \r\nL 229.595312 133.096875 \r\nL 229.595312 28.396875 \r\n\" style=\"fill:#f5fafe;stroke:#ffffff;stroke-width:0.5;\"/>\r\n    <path clip-path=\"url(#pdf9e02505e)\" d=\"M 42.395313 133.096875 \r\nL 229.595312 133.096875 \r\nL 229.595312 237.796875 \r\nL 42.395313 237.796875 \r\nL 42.395313 133.096875 \r\n\" style=\"fill:#f7fbff;stroke:#ffffff;stroke-width:0.5;\"/>\r\n    <path clip-path=\"url(#pdf9e02505e)\" d=\"M 229.595312 133.096875 \r\nL 416.795312 133.096875 \r\nL 416.795312 237.796875 \r\nL 229.595312 237.796875 \r\nL 229.595312 133.096875 \r\n\" style=\"fill:#e8f1fa;stroke:#ffffff;stroke-width:0.5;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m92e4f0b9f1\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"135.995313\" xlink:href=\"#m92e4f0b9f1\" y=\"237.796875\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- RFI -->\r\n      <g transform=\"translate(128.170313 252.395313)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 44.390625 34.1875 \r\nQ 47.5625 33.109375 50.5625 29.59375 \r\nQ 53.5625 26.078125 56.59375 19.921875 \r\nL 66.609375 0 \r\nL 56 0 \r\nL 46.6875 18.703125 \r\nQ 43.0625 26.03125 39.671875 28.421875 \r\nQ 36.28125 30.8125 30.421875 30.8125 \r\nL 19.671875 30.8125 \r\nL 19.671875 0 \r\nL 9.8125 0 \r\nL 9.8125 72.90625 \r\nL 32.078125 72.90625 \r\nQ 44.578125 72.90625 50.734375 67.671875 \r\nQ 56.890625 62.453125 56.890625 51.90625 \r\nQ 56.890625 45.015625 53.6875 40.46875 \r\nQ 50.484375 35.9375 44.390625 34.1875 \r\nz\r\nM 19.671875 64.796875 \r\nL 19.671875 38.921875 \r\nL 32.078125 38.921875 \r\nQ 39.203125 38.921875 42.84375 42.21875 \r\nQ 46.484375 45.515625 46.484375 51.90625 \r\nQ 46.484375 58.296875 42.84375 61.546875 \r\nQ 39.203125 64.796875 32.078125 64.796875 \r\nz\r\n\" id=\"DejaVuSans-82\"/>\r\n        <path d=\"M 9.8125 72.90625 \r\nL 51.703125 72.90625 \r\nL 51.703125 64.59375 \r\nL 19.671875 64.59375 \r\nL 19.671875 43.109375 \r\nL 48.578125 43.109375 \r\nL 48.578125 34.8125 \r\nL 19.671875 34.8125 \r\nL 19.671875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-70\"/>\r\n        <path d=\"M 9.8125 72.90625 \r\nL 19.671875 72.90625 \r\nL 19.671875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-73\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-82\"/>\r\n       <use x=\"69.482422\" xlink:href=\"#DejaVuSans-70\"/>\r\n       <use x=\"127.001953\" xlink:href=\"#DejaVuSans-73\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"323.195312\" xlink:href=\"#m92e4f0b9f1\" y=\"237.796875\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- Pulsar -->\r\n      <g transform=\"translate(307.985937 252.395313)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 19.671875 64.796875 \r\nL 19.671875 37.40625 \r\nL 32.078125 37.40625 \r\nQ 38.96875 37.40625 42.71875 40.96875 \r\nQ 46.484375 44.53125 46.484375 51.125 \r\nQ 46.484375 57.671875 42.71875 61.234375 \r\nQ 38.96875 64.796875 32.078125 64.796875 \r\nz\r\nM 9.8125 72.90625 \r\nL 32.078125 72.90625 \r\nQ 44.34375 72.90625 50.609375 67.359375 \r\nQ 56.890625 61.8125 56.890625 51.125 \r\nQ 56.890625 40.328125 50.609375 34.8125 \r\nQ 44.34375 29.296875 32.078125 29.296875 \r\nL 19.671875 29.296875 \r\nL 19.671875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-80\"/>\r\n        <path d=\"M 8.5 21.578125 \r\nL 8.5 54.6875 \r\nL 17.484375 54.6875 \r\nL 17.484375 21.921875 \r\nQ 17.484375 14.15625 20.5 10.265625 \r\nQ 23.53125 6.390625 29.59375 6.390625 \r\nQ 36.859375 6.390625 41.078125 11.03125 \r\nQ 45.3125 15.671875 45.3125 23.6875 \r\nL 45.3125 54.6875 \r\nL 54.296875 54.6875 \r\nL 54.296875 0 \r\nL 45.3125 0 \r\nL 45.3125 8.40625 \r\nQ 42.046875 3.421875 37.71875 1 \r\nQ 33.40625 -1.421875 27.6875 -1.421875 \r\nQ 18.265625 -1.421875 13.375 4.4375 \r\nQ 8.5 10.296875 8.5 21.578125 \r\nz\r\nM 31.109375 56 \r\nz\r\n\" id=\"DejaVuSans-117\"/>\r\n        <path d=\"M 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\n\" id=\"DejaVuSans-108\"/>\r\n        <path d=\"M 44.28125 53.078125 \r\nL 44.28125 44.578125 \r\nQ 40.484375 46.53125 36.375 47.5 \r\nQ 32.28125 48.484375 27.875 48.484375 \r\nQ 21.1875 48.484375 17.84375 46.4375 \r\nQ 14.5 44.390625 14.5 40.28125 \r\nQ 14.5 37.15625 16.890625 35.375 \r\nQ 19.28125 33.59375 26.515625 31.984375 \r\nL 29.59375 31.296875 \r\nQ 39.15625 29.25 43.1875 25.515625 \r\nQ 47.21875 21.78125 47.21875 15.09375 \r\nQ 47.21875 7.46875 41.1875 3.015625 \r\nQ 35.15625 -1.421875 24.609375 -1.421875 \r\nQ 20.21875 -1.421875 15.453125 -0.5625 \r\nQ 10.6875 0.296875 5.421875 2 \r\nL 5.421875 11.28125 \r\nQ 10.40625 8.6875 15.234375 7.390625 \r\nQ 20.0625 6.109375 24.8125 6.109375 \r\nQ 31.15625 6.109375 34.5625 8.28125 \r\nQ 37.984375 10.453125 37.984375 14.40625 \r\nQ 37.984375 18.0625 35.515625 20.015625 \r\nQ 33.0625 21.96875 24.703125 23.78125 \r\nL 21.578125 24.515625 \r\nQ 13.234375 26.265625 9.515625 29.90625 \r\nQ 5.8125 33.546875 5.8125 39.890625 \r\nQ 5.8125 47.609375 11.28125 51.796875 \r\nQ 16.75 56 26.8125 56 \r\nQ 31.78125 56 36.171875 55.265625 \r\nQ 40.578125 54.546875 44.28125 53.078125 \r\nz\r\n\" id=\"DejaVuSans-115\"/>\r\n        <path d=\"M 34.28125 27.484375 \r\nQ 23.390625 27.484375 19.1875 25 \r\nQ 14.984375 22.515625 14.984375 16.5 \r\nQ 14.984375 11.71875 18.140625 8.90625 \r\nQ 21.296875 6.109375 26.703125 6.109375 \r\nQ 34.1875 6.109375 38.703125 11.40625 \r\nQ 43.21875 16.703125 43.21875 25.484375 \r\nL 43.21875 27.484375 \r\nz\r\nM 52.203125 31.203125 \r\nL 52.203125 0 \r\nL 43.21875 0 \r\nL 43.21875 8.296875 \r\nQ 40.140625 3.328125 35.546875 0.953125 \r\nQ 30.953125 -1.421875 24.3125 -1.421875 \r\nQ 15.921875 -1.421875 10.953125 3.296875 \r\nQ 6 8.015625 6 15.921875 \r\nQ 6 25.140625 12.171875 29.828125 \r\nQ 18.359375 34.515625 30.609375 34.515625 \r\nL 43.21875 34.515625 \r\nL 43.21875 35.40625 \r\nQ 43.21875 41.609375 39.140625 45 \r\nQ 35.0625 48.390625 27.6875 48.390625 \r\nQ 23 48.390625 18.546875 47.265625 \r\nQ 14.109375 46.140625 10.015625 43.890625 \r\nL 10.015625 52.203125 \r\nQ 14.9375 54.109375 19.578125 55.046875 \r\nQ 24.21875 56 28.609375 56 \r\nQ 40.484375 56 46.34375 49.84375 \r\nQ 52.203125 43.703125 52.203125 31.203125 \r\nz\r\n\" id=\"DejaVuSans-97\"/>\r\n        <path d=\"M 41.109375 46.296875 \r\nQ 39.59375 47.171875 37.8125 47.578125 \r\nQ 36.03125 48 33.890625 48 \r\nQ 26.265625 48 22.1875 43.046875 \r\nQ 18.109375 38.09375 18.109375 28.8125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 20.953125 51.171875 25.484375 53.578125 \r\nQ 30.03125 56 36.53125 56 \r\nQ 37.453125 56 38.578125 55.875 \r\nQ 39.703125 55.765625 41.0625 55.515625 \r\nz\r\n\" id=\"DejaVuSans-114\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-80\"/>\r\n       <use x=\"58.552734\" xlink:href=\"#DejaVuSans-117\"/>\r\n       <use x=\"121.931641\" xlink:href=\"#DejaVuSans-108\"/>\r\n       <use x=\"149.714844\" xlink:href=\"#DejaVuSans-115\"/>\r\n       <use x=\"201.814453\" xlink:href=\"#DejaVuSans-97\"/>\r\n       <use x=\"263.09375\" xlink:href=\"#DejaVuSans-114\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_3\">\r\n     <!-- Predicted Class -->\r\n     <g transform=\"translate(172.275391 269.872656)scale(0.15 -0.15)\">\r\n      <defs>\r\n       <path d=\"M 56.203125 29.59375 \r\nL 56.203125 25.203125 \r\nL 14.890625 25.203125 \r\nQ 15.484375 15.921875 20.484375 11.0625 \r\nQ 25.484375 6.203125 34.421875 6.203125 \r\nQ 39.59375 6.203125 44.453125 7.46875 \r\nQ 49.3125 8.734375 54.109375 11.28125 \r\nL 54.109375 2.78125 \r\nQ 49.265625 0.734375 44.1875 -0.34375 \r\nQ 39.109375 -1.421875 33.890625 -1.421875 \r\nQ 20.796875 -1.421875 13.15625 6.1875 \r\nQ 5.515625 13.8125 5.515625 26.8125 \r\nQ 5.515625 40.234375 12.765625 48.109375 \r\nQ 20.015625 56 32.328125 56 \r\nQ 43.359375 56 49.78125 48.890625 \r\nQ 56.203125 41.796875 56.203125 29.59375 \r\nz\r\nM 47.21875 32.234375 \r\nQ 47.125 39.59375 43.09375 43.984375 \r\nQ 39.0625 48.390625 32.421875 48.390625 \r\nQ 24.90625 48.390625 20.390625 44.140625 \r\nQ 15.875 39.890625 15.1875 32.171875 \r\nz\r\n\" id=\"DejaVuSans-101\"/>\r\n       <path d=\"M 45.40625 46.390625 \r\nL 45.40625 75.984375 \r\nL 54.390625 75.984375 \r\nL 54.390625 0 \r\nL 45.40625 0 \r\nL 45.40625 8.203125 \r\nQ 42.578125 3.328125 38.25 0.953125 \r\nQ 33.9375 -1.421875 27.875 -1.421875 \r\nQ 17.96875 -1.421875 11.734375 6.484375 \r\nQ 5.515625 14.40625 5.515625 27.296875 \r\nQ 5.515625 40.1875 11.734375 48.09375 \r\nQ 17.96875 56 27.875 56 \r\nQ 33.9375 56 38.25 53.625 \r\nQ 42.578125 51.265625 45.40625 46.390625 \r\nz\r\nM 14.796875 27.296875 \r\nQ 14.796875 17.390625 18.875 11.75 \r\nQ 22.953125 6.109375 30.078125 6.109375 \r\nQ 37.203125 6.109375 41.296875 11.75 \r\nQ 45.40625 17.390625 45.40625 27.296875 \r\nQ 45.40625 37.203125 41.296875 42.84375 \r\nQ 37.203125 48.484375 30.078125 48.484375 \r\nQ 22.953125 48.484375 18.875 42.84375 \r\nQ 14.796875 37.203125 14.796875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-100\"/>\r\n       <path d=\"M 9.421875 54.6875 \r\nL 18.40625 54.6875 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\nM 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 64.59375 \r\nL 9.421875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-105\"/>\r\n       <path d=\"M 48.78125 52.59375 \r\nL 48.78125 44.1875 \r\nQ 44.96875 46.296875 41.140625 47.34375 \r\nQ 37.3125 48.390625 33.40625 48.390625 \r\nQ 24.65625 48.390625 19.8125 42.84375 \r\nQ 14.984375 37.3125 14.984375 27.296875 \r\nQ 14.984375 17.28125 19.8125 11.734375 \r\nQ 24.65625 6.203125 33.40625 6.203125 \r\nQ 37.3125 6.203125 41.140625 7.25 \r\nQ 44.96875 8.296875 48.78125 10.40625 \r\nL 48.78125 2.09375 \r\nQ 45.015625 0.34375 40.984375 -0.53125 \r\nQ 36.96875 -1.421875 32.421875 -1.421875 \r\nQ 20.0625 -1.421875 12.78125 6.34375 \r\nQ 5.515625 14.109375 5.515625 27.296875 \r\nQ 5.515625 40.671875 12.859375 48.328125 \r\nQ 20.21875 56 33.015625 56 \r\nQ 37.15625 56 41.109375 55.140625 \r\nQ 45.0625 54.296875 48.78125 52.59375 \r\nz\r\n\" id=\"DejaVuSans-99\"/>\r\n       <path d=\"M 18.3125 70.21875 \r\nL 18.3125 54.6875 \r\nL 36.8125 54.6875 \r\nL 36.8125 47.703125 \r\nL 18.3125 47.703125 \r\nL 18.3125 18.015625 \r\nQ 18.3125 11.328125 20.140625 9.421875 \r\nQ 21.96875 7.515625 27.59375 7.515625 \r\nL 36.8125 7.515625 \r\nL 36.8125 0 \r\nL 27.59375 0 \r\nQ 17.1875 0 13.234375 3.875 \r\nQ 9.28125 7.765625 9.28125 18.015625 \r\nL 9.28125 47.703125 \r\nL 2.6875 47.703125 \r\nL 2.6875 54.6875 \r\nL 9.28125 54.6875 \r\nL 9.28125 70.21875 \r\nz\r\n\" id=\"DejaVuSans-116\"/>\r\n       <path id=\"DejaVuSans-32\"/>\r\n       <path d=\"M 64.40625 67.28125 \r\nL 64.40625 56.890625 \r\nQ 59.421875 61.53125 53.78125 63.8125 \r\nQ 48.140625 66.109375 41.796875 66.109375 \r\nQ 29.296875 66.109375 22.65625 58.46875 \r\nQ 16.015625 50.828125 16.015625 36.375 \r\nQ 16.015625 21.96875 22.65625 14.328125 \r\nQ 29.296875 6.6875 41.796875 6.6875 \r\nQ 48.140625 6.6875 53.78125 8.984375 \r\nQ 59.421875 11.28125 64.40625 15.921875 \r\nL 64.40625 5.609375 \r\nQ 59.234375 2.09375 53.4375 0.328125 \r\nQ 47.65625 -1.421875 41.21875 -1.421875 \r\nQ 24.65625 -1.421875 15.125 8.703125 \r\nQ 5.609375 18.84375 5.609375 36.375 \r\nQ 5.609375 53.953125 15.125 64.078125 \r\nQ 24.65625 74.21875 41.21875 74.21875 \r\nQ 47.75 74.21875 53.53125 72.484375 \r\nQ 59.328125 70.75 64.40625 67.28125 \r\nz\r\n\" id=\"DejaVuSans-67\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-80\"/>\r\n      <use x=\"58.552734\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"97.416016\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"158.939453\" xlink:href=\"#DejaVuSans-100\"/>\r\n      <use x=\"222.416016\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"250.199219\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"305.179688\" xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"344.388672\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"405.912109\" xlink:href=\"#DejaVuSans-100\"/>\r\n      <use x=\"469.388672\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"501.175781\" xlink:href=\"#DejaVuSans-67\"/>\r\n      <use x=\"571\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"598.783203\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"660.0625\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"712.162109\" xlink:href=\"#DejaVuSans-115\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_3\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m75206c993d\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.395313\" xlink:href=\"#m75206c993d\" y=\"80.746875\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- RFI -->\r\n      <g transform=\"translate(33.315625 92.597656)rotate(-90)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-82\"/>\r\n       <use x=\"69.482422\" xlink:href=\"#DejaVuSans-70\"/>\r\n       <use x=\"127.001953\" xlink:href=\"#DejaVuSans-73\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.395313\" xlink:href=\"#m75206c993d\" y=\"185.446875\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- Pulsar -->\r\n      <g transform=\"translate(33.315625 212.066406)rotate(-90)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-80\"/>\r\n       <use x=\"58.552734\" xlink:href=\"#DejaVuSans-117\"/>\r\n       <use x=\"121.931641\" xlink:href=\"#DejaVuSans-108\"/>\r\n       <use x=\"149.714844\" xlink:href=\"#DejaVuSans-115\"/>\r\n       <use x=\"201.814453\" xlink:href=\"#DejaVuSans-97\"/>\r\n       <use x=\"263.09375\" xlink:href=\"#DejaVuSans-114\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_6\">\r\n     <!-- Actual Class -->\r\n     <g transform=\"translate(18.597656 178.707422)rotate(-90)scale(0.15 -0.15)\">\r\n      <defs>\r\n       <path d=\"M 34.1875 63.1875 \r\nL 20.796875 26.90625 \r\nL 47.609375 26.90625 \r\nz\r\nM 28.609375 72.90625 \r\nL 39.796875 72.90625 \r\nL 67.578125 0 \r\nL 57.328125 0 \r\nL 50.6875 18.703125 \r\nL 17.828125 18.703125 \r\nL 11.1875 0 \r\nL 0.78125 0 \r\nz\r\n\" id=\"DejaVuSans-65\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-65\"/>\r\n      <use x=\"66.658203\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"121.638672\" xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"160.847656\" xlink:href=\"#DejaVuSans-117\"/>\r\n      <use x=\"224.226562\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"285.505859\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"313.289062\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"345.076172\" xlink:href=\"#DejaVuSans-67\"/>\r\n      <use x=\"414.900391\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"442.683594\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"503.962891\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"556.0625\" xlink:href=\"#DejaVuSans-115\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"text_7\">\r\n    <!-- 3237 -->\r\n    <g style=\"fill:#ffffff;\" transform=\"translate(119.452813 84.334063)scale(0.13 -0.13)\">\r\n     <defs>\r\n      <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n      <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n      <path d=\"M 8.203125 72.90625 \r\nL 55.078125 72.90625 \r\nL 55.078125 68.703125 \r\nL 28.609375 0 \r\nL 18.3125 0 \r\nL 43.21875 64.59375 \r\nL 8.203125 64.59375 \r\nz\r\n\" id=\"DejaVuSans-55\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-51\"/>\r\n     <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\r\n     <use x=\"127.246094\" xlink:href=\"#DejaVuSans-51\"/>\r\n     <use x=\"190.869141\" xlink:href=\"#DejaVuSans-55\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"text_8\">\r\n    <!-- 53 -->\r\n    <g style=\"fill:#262626;\" transform=\"translate(314.924062 84.334063)scale(0.13 -0.13)\">\r\n     <defs>\r\n      <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-53\"/>\r\n     <use x=\"63.623047\" xlink:href=\"#DejaVuSans-51\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"text_9\">\r\n    <!-- 22 -->\r\n    <g style=\"fill:#262626;\" transform=\"translate(127.724063 189.034063)scale(0.13 -0.13)\">\r\n     <use xlink:href=\"#DejaVuSans-50\"/>\r\n     <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"text_10\">\r\n    <!-- 268 -->\r\n    <g style=\"fill:#262626;\" transform=\"translate(310.788437 189.034063)scale(0.13 -0.13)\">\r\n     <defs>\r\n      <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n      <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-50\"/>\r\n     <use x=\"63.623047\" xlink:href=\"#DejaVuSans-54\"/>\r\n     <use x=\"127.246094\" xlink:href=\"#DejaVuSans-56\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"text_11\">\r\n    <!-- Confusion Matrix -->\r\n    <g transform=\"translate(145.192187 22.396875)scale(0.2 -0.2)\">\r\n     <defs>\r\n      <path d=\"M 30.609375 48.390625 \r\nQ 23.390625 48.390625 19.1875 42.75 \r\nQ 14.984375 37.109375 14.984375 27.296875 \r\nQ 14.984375 17.484375 19.15625 11.84375 \r\nQ 23.34375 6.203125 30.609375 6.203125 \r\nQ 37.796875 6.203125 41.984375 11.859375 \r\nQ 46.1875 17.53125 46.1875 27.296875 \r\nQ 46.1875 37.015625 41.984375 42.703125 \r\nQ 37.796875 48.390625 30.609375 48.390625 \r\nz\r\nM 30.609375 56 \r\nQ 42.328125 56 49.015625 48.375 \r\nQ 55.71875 40.765625 55.71875 27.296875 \r\nQ 55.71875 13.875 49.015625 6.21875 \r\nQ 42.328125 -1.421875 30.609375 -1.421875 \r\nQ 18.84375 -1.421875 12.171875 6.21875 \r\nQ 5.515625 13.875 5.515625 27.296875 \r\nQ 5.515625 40.765625 12.171875 48.375 \r\nQ 18.84375 56 30.609375 56 \r\nz\r\n\" id=\"DejaVuSans-111\"/>\r\n      <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-110\"/>\r\n      <path d=\"M 37.109375 75.984375 \r\nL 37.109375 68.5 \r\nL 28.515625 68.5 \r\nQ 23.6875 68.5 21.796875 66.546875 \r\nQ 19.921875 64.59375 19.921875 59.515625 \r\nL 19.921875 54.6875 \r\nL 34.71875 54.6875 \r\nL 34.71875 47.703125 \r\nL 19.921875 47.703125 \r\nL 19.921875 0 \r\nL 10.890625 0 \r\nL 10.890625 47.703125 \r\nL 2.296875 47.703125 \r\nL 2.296875 54.6875 \r\nL 10.890625 54.6875 \r\nL 10.890625 58.5 \r\nQ 10.890625 67.625 15.140625 71.796875 \r\nQ 19.390625 75.984375 28.609375 75.984375 \r\nz\r\n\" id=\"DejaVuSans-102\"/>\r\n      <path d=\"M 9.8125 72.90625 \r\nL 24.515625 72.90625 \r\nL 43.109375 23.296875 \r\nL 61.8125 72.90625 \r\nL 76.515625 72.90625 \r\nL 76.515625 0 \r\nL 66.890625 0 \r\nL 66.890625 64.015625 \r\nL 48.09375 14.015625 \r\nL 38.1875 14.015625 \r\nL 19.390625 64.015625 \r\nL 19.390625 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-77\"/>\r\n      <path d=\"M 54.890625 54.6875 \r\nL 35.109375 28.078125 \r\nL 55.90625 0 \r\nL 45.3125 0 \r\nL 29.390625 21.484375 \r\nL 13.484375 0 \r\nL 2.875 0 \r\nL 24.125 28.609375 \r\nL 4.6875 54.6875 \r\nL 15.28125 54.6875 \r\nL 29.78125 35.203125 \r\nL 44.28125 54.6875 \r\nz\r\n\" id=\"DejaVuSans-120\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-67\"/>\r\n     <use x=\"69.824219\" xlink:href=\"#DejaVuSans-111\"/>\r\n     <use x=\"131.005859\" xlink:href=\"#DejaVuSans-110\"/>\r\n     <use x=\"194.384766\" xlink:href=\"#DejaVuSans-102\"/>\r\n     <use x=\"229.589844\" xlink:href=\"#DejaVuSans-117\"/>\r\n     <use x=\"292.96875\" xlink:href=\"#DejaVuSans-115\"/>\r\n     <use x=\"345.068359\" xlink:href=\"#DejaVuSans-105\"/>\r\n     <use x=\"372.851562\" xlink:href=\"#DejaVuSans-111\"/>\r\n     <use x=\"434.033203\" xlink:href=\"#DejaVuSans-110\"/>\r\n     <use x=\"497.412109\" xlink:href=\"#DejaVuSans-32\"/>\r\n     <use x=\"529.199219\" xlink:href=\"#DejaVuSans-77\"/>\r\n     <use x=\"615.478516\" xlink:href=\"#DejaVuSans-97\"/>\r\n     <use x=\"676.757812\" xlink:href=\"#DejaVuSans-116\"/>\r\n     <use x=\"715.966797\" xlink:href=\"#DejaVuSans-114\"/>\r\n     <use x=\"757.080078\" xlink:href=\"#DejaVuSans-105\"/>\r\n     <use x=\"784.863281\" xlink:href=\"#DejaVuSans-120\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pdf9e02505e\">\r\n   <rect height=\"209.4\" width=\"374.4\" x=\"42.395313\" y=\"28.396875\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "# Getting model predictions using the test input dataframe\n",
    "y_predict = neural_network.predict(x_test)\n",
    "\n",
    "# Accuracy Score\n",
    "print(\"Accuracy Score:\", end = \" \")\n",
    "print(accuracy_score(y_test, y_predict))\n",
    "\n",
    "# F1 Score\n",
    "print(\"F1 Score:\", end =\" \")\n",
    "print(f1_score(y_test, y_predict, average=None))\n",
    "\n",
    "\n",
    "# The rest of this block is the confusion matrix\n",
    "# If you just want a quick confusion matrix just use the following line:\n",
    "# confusion_matrix(y_predict, y_test)\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.title(\"Confusion Matrix\", fontsize=20)\n",
    "\n",
    "palette = sns.set_palette('pastel')\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_predict, y_test),cbar=False,annot=True, annot_kws={'size': 13}, fmt=\"d\", linewidth=.5, robust=True, xticklabels=['RFI','Pulsar'], yticklabels=['RFI', 'Pulsar'], cmap='Blues', vmax = 3225, vmin = 19)\n",
    "\n",
    "plt.xlabel('Predicted Class', fontsize=15)\n",
    "plt.ylabel('Actual Class', fontsize=15)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "source": [
    "# Start here"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "s\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=MLPClassifier(hidden_layer_sizes=(10, 10, 10)),\n",
       "             param_grid={'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
       "                         'solver': ['lbfgs', 'sgd', 'adam']})"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# 97% accuracy is pretty good\n",
    "\n",
    "# we can try other parameters to see if they do better\n",
    "# It is almost impossible to try all combinations by hand\n",
    "# there is a helpful method that lets us try different models \n",
    "\n",
    "# Grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Here we are comparing the 4 different values of activation and 3 different values for solver\n",
    "# Gridsearch will compare all possible combinations of these and return the best\n",
    "# The parameters are the model you want to use, a list of parameters you want to check, \n",
    "# cv and others you can look into\n",
    "# cv=5 basically splits the test data into 5 different tests and then it takes the average to rank them\n",
    "grid_search = GridSearchCV(MLPClassifier(hidden_layer_sizes=(10,10,10)),{\n",
    "    'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'solver': ['lbfgs', 'sgd', 'adam']\n",
    "}, cv=5, return_train_score=False)\n",
    "\n",
    "grid_search.fit(x_train, y_train.values.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       1.596066      0.115624         0.002993        0.000894   \n",
       "1       1.301678      1.364905         0.002821        0.000710   \n",
       "2       1.100885      0.148681         0.002769        0.000300   \n",
       "3       2.956254      0.393813         0.003860        0.000161   \n",
       "4       0.644134      0.028657         0.003397        0.000349   \n",
       "\n",
       "  param_activation param_solver  \\\n",
       "0         identity        lbfgs   \n",
       "1         identity          sgd   \n",
       "2         identity         adam   \n",
       "3         logistic        lbfgs   \n",
       "4         logistic          sgd   \n",
       "\n",
       "                                          params  split0_test_score  \\\n",
       "0  {'activation': 'identity', 'solver': 'lbfgs'}           0.981494   \n",
       "1    {'activation': 'identity', 'solver': 'sgd'}           0.973464   \n",
       "2   {'activation': 'identity', 'solver': 'adam'}           0.978701   \n",
       "3  {'activation': 'logistic', 'solver': 'lbfgs'}           0.980447   \n",
       "4    {'activation': 'logistic', 'solver': 'sgd'}           0.907821   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.975209           0.980440           0.974502           0.977995   \n",
       "1           0.907821           0.974153           0.970311           0.972057   \n",
       "2           0.972067           0.974502           0.971708           0.977297   \n",
       "3           0.971020           0.980440           0.974153           0.975201   \n",
       "4           0.907821           0.908138           0.908138           0.907789   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.977928        0.002763                1  \n",
       "1         0.959561        0.025903               11  \n",
       "2         0.974855        0.002777                6  \n",
       "3         0.976252        0.003689                2  \n",
       "4         0.907942        0.000161               12  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_activation</th>\n      <th>param_solver</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.596066</td>\n      <td>0.115624</td>\n      <td>0.002993</td>\n      <td>0.000894</td>\n      <td>identity</td>\n      <td>lbfgs</td>\n      <td>{'activation': 'identity', 'solver': 'lbfgs'}</td>\n      <td>0.981494</td>\n      <td>0.975209</td>\n      <td>0.980440</td>\n      <td>0.974502</td>\n      <td>0.977995</td>\n      <td>0.977928</td>\n      <td>0.002763</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.301678</td>\n      <td>1.364905</td>\n      <td>0.002821</td>\n      <td>0.000710</td>\n      <td>identity</td>\n      <td>sgd</td>\n      <td>{'activation': 'identity', 'solver': 'sgd'}</td>\n      <td>0.973464</td>\n      <td>0.907821</td>\n      <td>0.974153</td>\n      <td>0.970311</td>\n      <td>0.972057</td>\n      <td>0.959561</td>\n      <td>0.025903</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.100885</td>\n      <td>0.148681</td>\n      <td>0.002769</td>\n      <td>0.000300</td>\n      <td>identity</td>\n      <td>adam</td>\n      <td>{'activation': 'identity', 'solver': 'adam'}</td>\n      <td>0.978701</td>\n      <td>0.972067</td>\n      <td>0.974502</td>\n      <td>0.971708</td>\n      <td>0.977297</td>\n      <td>0.974855</td>\n      <td>0.002777</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.956254</td>\n      <td>0.393813</td>\n      <td>0.003860</td>\n      <td>0.000161</td>\n      <td>logistic</td>\n      <td>lbfgs</td>\n      <td>{'activation': 'logistic', 'solver': 'lbfgs'}</td>\n      <td>0.980447</td>\n      <td>0.971020</td>\n      <td>0.980440</td>\n      <td>0.974153</td>\n      <td>0.975201</td>\n      <td>0.976252</td>\n      <td>0.003689</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.644134</td>\n      <td>0.028657</td>\n      <td>0.003397</td>\n      <td>0.000349</td>\n      <td>logistic</td>\n      <td>sgd</td>\n      <td>{'activation': 'logistic', 'solver': 'sgd'}</td>\n      <td>0.907821</td>\n      <td>0.907821</td>\n      <td>0.908138</td>\n      <td>0.908138</td>\n      <td>0.907789</td>\n      <td>0.907942</td>\n      <td>0.000161</td>\n      <td>12</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# Easier to look at results if you save them to a dataframe (so we can manipulate the data with pandas mehtods)\n",
    "grid_search_results = pd.DataFrame(grid_search.cv_results_)\n",
    "grid_search_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        1.596066      0.115624         0.002993        0.000894   \n",
       "3        2.956254      0.393813         0.003860        0.000161   \n",
       "5        3.814097      0.661056         0.003260        0.000395   \n",
       "11       3.236132      1.485711         0.002957        0.000633   \n",
       "9        2.527177      0.211673         0.003866        0.001566   \n",
       "\n",
       "   param_activation param_solver  \\\n",
       "0          identity        lbfgs   \n",
       "3          logistic        lbfgs   \n",
       "5          logistic         adam   \n",
       "11             relu         adam   \n",
       "9              relu        lbfgs   \n",
       "\n",
       "                                           params  split0_test_score  \\\n",
       "0   {'activation': 'identity', 'solver': 'lbfgs'}           0.981494   \n",
       "3   {'activation': 'logistic', 'solver': 'lbfgs'}           0.980447   \n",
       "5    {'activation': 'logistic', 'solver': 'adam'}           0.979399   \n",
       "11       {'activation': 'relu', 'solver': 'adam'}           0.979399   \n",
       "9       {'activation': 'relu', 'solver': 'lbfgs'}           0.976257   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.975209           0.980440           0.974502   \n",
       "3            0.971020           0.980440           0.974153   \n",
       "5            0.974162           0.976947           0.974153   \n",
       "11           0.973115           0.976249           0.975899   \n",
       "9            0.973813           0.975550           0.974153   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.977995         0.977928        0.002763                1  \n",
       "3            0.975201         0.976252        0.003689                2  \n",
       "5            0.975899         0.976112        0.001959                3  \n",
       "11           0.973454         0.975623        0.002268                4  \n",
       "9            0.975201         0.974995        0.000900                5  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_activation</th>\n      <th>param_solver</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.596066</td>\n      <td>0.115624</td>\n      <td>0.002993</td>\n      <td>0.000894</td>\n      <td>identity</td>\n      <td>lbfgs</td>\n      <td>{'activation': 'identity', 'solver': 'lbfgs'}</td>\n      <td>0.981494</td>\n      <td>0.975209</td>\n      <td>0.980440</td>\n      <td>0.974502</td>\n      <td>0.977995</td>\n      <td>0.977928</td>\n      <td>0.002763</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.956254</td>\n      <td>0.393813</td>\n      <td>0.003860</td>\n      <td>0.000161</td>\n      <td>logistic</td>\n      <td>lbfgs</td>\n      <td>{'activation': 'logistic', 'solver': 'lbfgs'}</td>\n      <td>0.980447</td>\n      <td>0.971020</td>\n      <td>0.980440</td>\n      <td>0.974153</td>\n      <td>0.975201</td>\n      <td>0.976252</td>\n      <td>0.003689</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3.814097</td>\n      <td>0.661056</td>\n      <td>0.003260</td>\n      <td>0.000395</td>\n      <td>logistic</td>\n      <td>adam</td>\n      <td>{'activation': 'logistic', 'solver': 'adam'}</td>\n      <td>0.979399</td>\n      <td>0.974162</td>\n      <td>0.976947</td>\n      <td>0.974153</td>\n      <td>0.975899</td>\n      <td>0.976112</td>\n      <td>0.001959</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>3.236132</td>\n      <td>1.485711</td>\n      <td>0.002957</td>\n      <td>0.000633</td>\n      <td>relu</td>\n      <td>adam</td>\n      <td>{'activation': 'relu', 'solver': 'adam'}</td>\n      <td>0.979399</td>\n      <td>0.973115</td>\n      <td>0.976249</td>\n      <td>0.975899</td>\n      <td>0.973454</td>\n      <td>0.975623</td>\n      <td>0.002268</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2.527177</td>\n      <td>0.211673</td>\n      <td>0.003866</td>\n      <td>0.001566</td>\n      <td>relu</td>\n      <td>lbfgs</td>\n      <td>{'activation': 'relu', 'solver': 'lbfgs'}</td>\n      <td>0.976257</td>\n      <td>0.973813</td>\n      <td>0.975550</td>\n      <td>0.974153</td>\n      <td>0.975201</td>\n      <td>0.974995</td>\n      <td>0.000900</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# this gives us a bunch of helpful data\n",
    "# We can sort based on the rank of the different tests so it is in order of best to worst combinations\n",
    "# by tells us which column value we want to sort by\n",
    "# axis tells us which we are sorting (we want to sort the rows)\n",
    "# ascending is self explanitory\n",
    "grid_search_results = grid_search_results.sort_values(by=['rank_test_score'], axis=0, ascending=True)\n",
    "grid_search_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you wanted to save this dataframe use the following\n",
    "# you could use this to do further study on the results\n",
    "grid_search_results.to_csv('tutorialGridSearch.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The last thing I want to look at in this tutorial is the library pickle\n",
    "# This allows you to save trained models to your hard drive\n",
    "# you can use this to save the best models that could be used for further use\n",
    "import pickle\n",
    "\n",
    "# this is just creating a file to write to and dumping the pickle\n",
    "with open(os.path.join(here, 'tutorialGridsearch.pkl'), 'wb') as f:\n",
    "    pickle.dump(neural_network, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load a pickle do the following\n",
    "with open(os.path.join(here, 'tutorialGridsearch.pkl'), 'rb') as f:\n",
    "    pickled_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9787709497206704"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "# so directly from loading we can use it to predict again\n",
    "y_predict = pickled_model.predict(x_test)\n",
    "\n",
    "accuracy_score(y_test, y_predict)"
   ]
  }
 ]
}